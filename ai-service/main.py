import cv2
import mediapipe as mp
import numpy as np
import math
import time
import os
import asyncio
import base64
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
import uvicorn
from typing import Dict, List
import json

app = FastAPI()

# CORS middleware ƒë·ªÉ frontend c√≥ th·ªÉ k·∫øt n·ªëi
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class HandGestureRecognizer:
    def __init__(self):
        # Kh·ªüi t·∫°o MediaPipe v·ªõi settings t·ªëi ∆∞u
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=1,  # Ch·ªâ nh·∫≠n di·ªán 1 tay
            min_detection_confidence=0.6,  # Gi·∫£m ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
            min_tracking_confidence=0.4   # Gi·∫£m ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô
        )
        
        # C√°c bi·∫øn ƒëi·ªÅu khi·ªÉn
        self.zoom_level = 1.0  # M·ª©c zoom hi·ªán t·∫°i
        self.min_zoom = 1.0    # Zoom t·ªëi thi·ªÉu
        self.max_zoom = 3.0    # Zoom t·ªëi ƒëa
        self.zoom_step = 0.2   # TƒÉng b∆∞·ªõc nh·∫£y zoom ƒë·ªÉ ph·∫£n h·ªìi nhanh h∆°n
        
        # Bi·∫øn mode v√† capture
        self.mode = "OFF"  # OFF ho·∫∑c ON
        self.is_capturing = False
        self.captured_photos = []
        self.max_photos = 6
        self.countdown = 0
        self.last_ok_detection = 0
        self.ok_cooldown = 2.0  # 2 gi√¢y cooldown cho OK sign
        self.last_countdown_update = 0
        self.countdown_interval = 1.0  # 1 gi√¢y gi·ªØa c√°c countdown
        self.requires_ok_continuous = False  # Kh√¥ng y√™u c·∫ßu OK sign li√™n t·ª•c
        
        # T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh n·∫øu ch∆∞a c√≥
        if not os.path.exists('captured_images'):
            os.makedirs('captured_images')

    def calculate_distance(self, point1, point2):
        """T√≠nh kho·∫£ng c√°ch gi·ªØa 2 ƒëi·ªÉm landmark"""
        return math.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2)

    def is_finger_up(self, landmarks, tip_id, pip_id):
        """Ki·ªÉm tra ng√≥n tay c√≥ du·ªói th·∫≥ng kh√¥ng"""
        return landmarks[tip_id].y < landmarks[pip_id].y

    def recognize_gesture(self, landmarks):
        """
        Nh·∫≠n di·ªán c·ª≠ ch·ªâ tay d·ª±a tr√™n landmarks
        Returns: 'fist', 'open', 'ok', ho·∫∑c 'unknown'
        """
        # C√°c ch·ªâ s·ªë landmark quan tr·ªçng
        thumb_tip = 4
        thumb_ip = 3
        index_tip = 8
        index_pip = 6
        middle_tip = 12
        middle_pip = 10
        ring_tip = 16
        ring_pip = 14
        pinky_tip = 20
        pinky_pip = 18

        # Ki·ªÉm tra c√°c ng√≥n tay c√≥ du·ªói th·∫≥ng kh√¥ng
        fingers_up = []
        
        # Ng√≥n c√°i (ki·ªÉm tra theo chi·ªÅu ngang)
        if landmarks[thumb_tip].x > landmarks[thumb_ip].x:  # Tay ph·∫£i
            fingers_up.append(landmarks[thumb_tip].x > landmarks[thumb_ip].x)
        else:  # Tay tr√°i
            fingers_up.append(landmarks[thumb_tip].x < landmarks[thumb_ip].x)
        
        # 4 ng√≥n c√≤n l·∫°i
        for tip, pip in [(index_tip, index_pip), (middle_tip, middle_pip), 
                        (ring_tip, ring_pip), (pinky_tip, pinky_pip)]:
            fingers_up.append(self.is_finger_up(landmarks, tip, pip))

        fingers_up_count = fingers_up.count(True)

        # Nh·∫≠n di·ªán c·ª≠ ch·ªâ OK: ng√≥n c√°i v√† ng√≥n tr·ªè ch·∫°m nhau, c√°c ng√≥n kh√°c du·ªói
        thumb_index_distance = self.calculate_distance(landmarks[thumb_tip], landmarks[index_tip])
        
        if thumb_index_distance < 0.05:  # Ng√≥n c√°i v√† tr·ªè g·∫ßn nhau
            if fingers_up[2] and fingers_up[3] and fingers_up[4]:  # 3 ng√≥n c√≤n l·∫°i du·ªói
                return 'ok'

        # Nh·∫≠n di·ªán n·∫Øm tay: t·∫•t c·∫£ ng√≥n tay c·ª•p l·∫°i
        if fingers_up_count <= 1:
            return 'fist'
        
        # Nh·∫≠n di·ªán m·ªü tay: h·∫ßu h·∫øt ng√≥n tay du·ªói
        elif fingers_up_count >= 4:
            return 'open'
        
        return 'unknown'

    def apply_zoom(self, frame):
        """√Åp d·ª•ng zoom v√†o frame"""
        if self.zoom_level == 1.0:
            return frame
        
        h, w = frame.shape[:2]
        
        # T√≠nh to√°n v√πng crop ƒë·ªÉ zoom
        crop_h = int(h / self.zoom_level)
        crop_w = int(w / self.zoom_level)
        
        start_x = (w - crop_w) // 2
        start_y = (h - crop_h) // 2
        
        # Crop v√† resize v·ªÅ k√≠ch th∆∞·ªõc ban ƒë·∫ßu
        cropped = frame[start_y:start_y + crop_h, start_x:start_x + crop_w]
        zoomed = cv2.resize(cropped, (w, h))
        
        return zoomed

    def capture_image(self, frame):
        """Ch·ª•p v√† l∆∞u ·∫£nh"""
        if len(self.captured_photos) >= self.max_photos:
            return False
            
        timestamp = int(time.time() * 1000)
        filename = f'captured_images/capture_{timestamp}.jpg'
        cv2.imwrite(filename, frame)
        
        # Encode ·∫£nh th√†nh base64 ƒë·ªÉ g·ª≠i qua WebSocket (ch·∫•t l∆∞·ª£ng cao)
        _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 90])
        img_base64 = base64.b64encode(buffer).decode('utf-8')
        
        photo_data = {
            'id': str(timestamp),
            'dataUrl': f'data:image/jpeg;base64,{img_base64}',
            'timestamp': timestamp
        }
        
        self.captured_photos.append(photo_data)
        print(f"üì∏ ƒê√£ ch·ª•p ·∫£nh: {filename} ({len(self.captured_photos)}/{self.max_photos})")
        return True

    def process_frame(self, frame):
        """X·ª≠ l√Ω frame v√† tr·∫£ v·ªÅ th√¥ng tin c·∫ßn thi·∫øt (t·ªëi ∆∞u t·ªëc ƒë·ªô)"""
        # L·∫≠t frame theo chi·ªÅu ngang ƒë·ªÉ c√≥ c·∫£m gi√°c nh∆∞ nh√¨n g∆∞∆°ng
        frame = cv2.flip(frame, 1)
        h, w, c = frame.shape
        
        # Resize frame ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω
        small_frame = cv2.resize(frame, (320, 240))
        
        # Chuy·ªÉn ƒë·ªïi BGR sang RGB cho MediaPipe
        rgb_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        
        # X·ª≠ l√Ω nh·∫≠n di·ªán tay
        results = self.hands.process(rgb_frame)
        
        gesture = 'unknown'
        current_time = time.time()
        
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                # Nh·∫≠n di·ªán c·ª≠ ch·ªâ
                gesture = self.recognize_gesture(hand_landmarks.landmark)
                
                # X·ª≠ l√Ω c√°c h√†nh ƒë·ªông d·ª±a tr√™n c·ª≠ ch·ªâ
                if gesture == 'fist':
                    # Zoom out
                    if self.zoom_level > self.min_zoom:
                        self.zoom_level = max(self.min_zoom, self.zoom_level - self.zoom_step)
                
                elif gesture == 'open':
                    # Zoom in
                    if self.zoom_level < self.max_zoom:
                        self.zoom_level = min(self.max_zoom, self.zoom_level + self.zoom_step)
                
                elif gesture == 'ok':
                    # OK sign - chuy·ªÉn mode ON v√† b·∫Øt ƒë·∫ßu ch·ª•p ·∫£nh (ch·ªâ c·∫ßn 1 l·∫ßn)
                    if current_time - self.last_ok_detection > self.ok_cooldown:
                        self.last_ok_detection = current_time
                        if self.mode == "OFF" and not self.is_capturing:
                            self.mode = "ON"
                            self.is_capturing = True
                            self.countdown = 5  # 5 gi√¢y countdown
                            self.last_countdown_update = current_time
                            print("üîÑ Chuy·ªÉn Mode: ON - B·∫Øt ƒë·∫ßu countdown...")
        
        # X·ª≠ l√Ω countdown v√† ch·ª•p ·∫£nh v·ªõi timer ch√≠nh x√°c
        if self.is_capturing and self.countdown > 0:
            # Ch·ªâ gi·∫£m countdown m·ªói gi√¢y, kh√¥ng ph·∫£i m·ªói frame
            if current_time - self.last_countdown_update >= self.countdown_interval:
                self.countdown -= 1
                self.last_countdown_update = current_time
                print(f"‚è∞ Countdown: {self.countdown}")
                
                if self.countdown == 0:
                    if self.capture_image(frame):
                        if len(self.captured_photos) < self.max_photos:
                            self.countdown = 5  # Ti·∫øp t·ª•c countdown 5 gi√¢y cho ·∫£nh ti·∫øp theo
                            self.last_countdown_update = current_time
                            print(f"üì∏ Ch·ª•p ·∫£nh {len(self.captured_photos)}/{self.max_photos} - Ti·∫øp t·ª•c countdown...")
                        else:
                            self.is_capturing = False
                            self.mode = "OFF"
                            self.countdown = 0
                            print("‚úÖ Ho√†n th√†nh ch·ª•p 6 ·∫£nh - Chuy·ªÉn Mode: OFF")
                    else:
                        self.is_capturing = False
                        self.mode = "OFF"
                        self.countdown = 0
                        print("‚ùå L·ªói ch·ª•p ·∫£nh - Chuy·ªÉn Mode: OFF")
        
        # Kh√¥ng c·∫ßn ki·ªÉm tra OK sign timeout v√¨ kh√¥ng y√™u c·∫ßu li√™n t·ª•c
        
        # √Åp d·ª•ng zoom
        display_frame = self.apply_zoom(frame)
        
        # Encode frame ƒë·ªÉ g·ª≠i qua WebSocket (gi·ªØ ch·∫•t l∆∞·ª£ng cao)
        _, buffer = cv2.imencode('.jpg', display_frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
        frame_base64 = base64.b64encode(buffer).decode('utf-8')
        
        return {
            'frame': f'data:image/jpeg;base64,{frame_base64}',
            'gesture': gesture,
            'zoom_level': round(self.zoom_level, 1),
            'mode': self.mode,
            'is_capturing': self.is_capturing,
            'countdown': self.countdown,
            'captured_photos': self.captured_photos,
            'photos_count': len(self.captured_photos)
        }

# Kh·ªüi t·∫°o recognizer
recognizer = HandGestureRecognizer()

# WebSocket connection manager
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            try:
                await connection.send_text(message)
            except:
                pass

manager = ConnectionManager()

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    print("üîå Client connected to WebSocket")
    
    # Kh·ªüi t·∫°o camera v·ªõi settings c√¢n b·∫±ng ch·∫•t l∆∞·ª£ng v√† t·ªëc ƒë·ªô
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)  # ƒê·ªô ph√¢n gi·∫£i cao cho ch·∫•t l∆∞·ª£ng t·ªët
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)  # ƒê·ªô ph√¢n gi·∫£i cao cho ch·∫•t l∆∞·ª£ng t·ªët
    cap.set(cv2.CAP_PROP_FPS, 30)            # FPS ·ªïn ƒë·ªãnh
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)      # Gi·∫£m buffer ƒë·ªÉ gi·∫£m delay
    
    if not cap.isOpened():
        await websocket.send_text(json.dumps({"error": "Cannot open camera"}))
        return
    
    try:
        while True:
            success, frame = cap.read()
            if not success:
                break
            
            # X·ª≠ l√Ω frame
            result = recognizer.process_frame(frame)
            
            # G·ª≠i k·∫øt qu·∫£ qua WebSocket
            await websocket.send_text(json.dumps(result))
            
            # Delay nh·ªè ƒë·ªÉ tr√°nh qu√° t·∫£i (FPS ·ªïn ƒë·ªãnh)
            await asyncio.sleep(0.033)  # ~30 FPS
            
    except WebSocketDisconnect:
        print("üîå Client disconnected from WebSocket")
    except Exception as e:
        print(f"‚ùå WebSocket error: {e}")
    finally:
        cap.release()
        manager.disconnect(websocket)

@app.post("/toggle_mode")
async def toggle_mode():
    """API ƒë·ªÉ toggle mode ON/OFF"""
    current_time = time.time()
    
    if recognizer.mode == "OFF" and not recognizer.is_capturing:
        recognizer.mode = "ON"
        recognizer.is_capturing = True
        recognizer.countdown = 5
        recognizer.last_countdown_update = current_time
        print("üîÑ Mode switched to ON - Manual toggle")
    elif recognizer.mode == "ON" or recognizer.is_capturing:
        recognizer.mode = "OFF"
        recognizer.is_capturing = False
        recognizer.countdown = 0
        print("üîÑ Mode switched to OFF - Manual toggle")
    
    return {
        "mode": recognizer.mode,
        "is_capturing": recognizer.is_capturing,
        "countdown": recognizer.countdown
    }

@app.get("/status")
async def get_status():
    """API ƒë·ªÉ l·∫•y tr·∫°ng th√°i hi·ªán t·∫°i"""
    return {
        "mode": recognizer.mode,
        "zoom_level": recognizer.zoom_level,
        "is_capturing": recognizer.is_capturing,
        "countdown": recognizer.countdown,
        "photos_count": len(recognizer.captured_photos),
        "max_photos": recognizer.max_photos
    }

@app.post("/reset")
async def reset_photos():
    """API ƒë·ªÉ reset t·∫•t c·∫£ ·∫£nh ƒë√£ ch·ª•p"""
    recognizer.captured_photos = []
    recognizer.mode = "OFF"
    recognizer.is_capturing = False
    recognizer.countdown = 0
    recognizer.last_ok_detection = 0
    recognizer.last_countdown_update = 0
    print("üîÑ Reset photos and mode")
    return {"message": "Reset successful"}

@app.get("/")
async def root():
    return {"message": "Photobooth AI Backend is running!"}

if __name__ == "__main__":
    print("üöÄ Starting Photobooth AI Backend...")
    print("üìã Features:")
    print("   üëä Fist ‚Üí Zoom Out (1x-3x)")
    print("   ‚úã Open Hand ‚Üí Zoom In (1x-3x)")
    print("   üëå OK Sign ‚Üí Auto Mode ON + Capture 6 photos")
    print("   üîÑ Mode Toggle: OFF (gesture only) / ON (capture mode)")
    print("üåê WebSocket: ws://localhost:8000/ws")
    print("üåê API: http://localhost:8000")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
